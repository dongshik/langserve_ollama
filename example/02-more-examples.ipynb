{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë²ˆì—­ê¸°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langserve import RemoteRunnable\n",
    "\n",
    "# ngrok remote ì£¼ì†Œ ì„¤ì •\n",
    "# chain = RemoteRunnable(\"https://poodle-deep-marmot.ngrok-free.app/translate/\")\n",
    "# chain = RemoteRunnable(\"NGROK ì—ì„œ ì„¤ì •í•œ ë³¸ì¸ì˜ ë„ë©”ì¸ ì£¼ì†Œ/translate/\")\n",
    "chain = RemoteRunnable(\"https://humble-curiously-antelope.ngrok-free.app/translate/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì €ëŠ” ë”¥ëŸ¬ë‹ì„ ì‚¬ë‘í•©ë‹ˆë‹¤"
     ]
    }
   ],
   "source": [
    "for token in chain.stream({\"input\": \"I love deep learning\"}):\n",
    "    print(token, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM ì„ Runnableë¡œ ì‹¤í–‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langserve import RemoteRunnable\n",
    "\n",
    "# llm = RemoteRunnable(\"https://poodle-deep-marmot.ngrok-free.app/llm/\")\n",
    "# llm = RemoteRunnable(\"NGROK ì—ì„œ ì„¤ì •í•œ ë³¸ì¸ì˜ ë„ë©”ì¸ ì£¼ì†Œ/llm/\")\n",
    "llm = RemoteRunnable(\"https://humble-curiously-antelope.ngrok-free.app/llm/\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"ë‹¤ìŒì˜ ë‚´ìš©ì„ SNS ê²Œì‹œê¸€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ ì£¼ì„¸ìš”:\\n{input}\"\n",
    ")\n",
    "\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ğŸ’¡ AI ì–´ì‹œìŠ¤í„´íŠ¸ë¡œì„œ ì €ëŠ” ë”¥ëŸ¬ë‹ì— ëŒ€í•œ ì‚¬ë‘ì„ í‘œí˜„í•˜ê³  ì‹¶ì–´ ì—¬ëŸ¬ë¶„ì„ ìœ„í•œ ì†Œì…œ ë¯¸ë””ì–´ ê²Œì‹œë¬¼ì„ ë§Œë“¤ì–´ ë³´ì•˜ìŠµë‹ˆë‹¤! ì—¬ê¸° ìˆìŠµë‹ˆë‹¤:\\n\\nğŸš€ \"ì¸ê³µì§€ëŠ¥ì˜ ì„¸ê³„ê°€ ì €ë¥¼ ë§¤ë£Œì‹œí‚¨ ê²ƒì€ ë°”ë¡œ ë”¥ëŸ¬ë‹ì´ì—ìš”! ë³µì¡í•œ ë°ì´í„° ì„¸íŠ¸ë¥¼ ë¶„ì„í•˜ê³ , í•™ìŠµí•˜ë©°, ì˜ˆì¸¡ì„ í•˜ëŠ” ëŠ¥ë ¥ì€ ì •ë§ ë†€ë¼ì›Œìš”. ì´ ê°•ë ¥í•œ ê¸°ìˆ ì„ í†µí•´ ìš°ë¦¬ëŠ” ì„¸ìƒì„ ë³€í™”ì‹œí‚¬ ìˆ˜ ìˆëŠ” ë¬´ìˆ˜í•œ ê°€ëŠ¥ì„±ì„ ì—´ê²Œ ë˜ì—ˆì£ . ì—¬ëŸ¬ë¶„ë„ ì €ì™€ í•¨ê»˜ ë”¥ëŸ¬ë‹ì— ëŒ€í•œ ì‚¬ë‘ì„ ë‚˜ëˆ„ê³  ì‹¶ìœ¼ì‹ ê°€ìš”? #DeepLearningLove #AIForAll\"\\n\\nì´ ê²Œì‹œë¬¼ì„ ì—¬ëŸ¬ë¶„ì˜ ì†Œì…œ ë¯¸ë””ì–´ í”Œë«í¼ì— ê³µìœ í•˜ì—¬ AI ì»¤ë®¤ë‹ˆí‹°ì™€ ì—°ê²°í•˜ê³ , ë”¥ëŸ¬ë‹ì˜ í˜ì„ ì¶•í•˜í•˜ì„¸ìš”! ğŸ¤–ğŸ’»'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"ì €ëŠ” ë”¥ëŸ¬ë‹ì„ ë„ˆë¬´ë‚˜ë„ ì‚¬ë‘í•©ë‹ˆë‹¤.\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
